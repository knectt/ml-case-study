{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#External code comes essentially from my IBM ML course, Pytorch website \n#and various coding forums (including chatGPT) ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PyTorch Library\nimport torch \n# PyTorch Neural Network\nimport torch.nn as nn\n# Allows us to transform data\nimport torchvision.transforms as transforms\n# Allows us to get the digit dataset\nimport torchvision.datasets as dsets\n# Creating graphs\nimport matplotlib.pylab as plt\n# Allows us to use arrays to manipulate and store data\nimport numpy as np\n# Memory monitoring\nimport psutil\n\nimport time\n# Allows quantization from float32 to 16\nimport torch.quantization","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_data(data_sample):\n    plt.imshow(data_sample[0].numpy().reshape(28, 28), cmap='gray')\n    plt.title('y = ' + str(data_sample[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Download Train and Validation datasets","metadata":{}},{"cell_type":"code","source":"train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\nprint(\"Print the training dataset:\\n \", train_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_dataset = dsets.MNIST(root='./data', download=True, train=False,transform=transforms.ToTensor())\nprint(\"Print the validation dataset:\\n \", validation_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Print first image in train and validation","metadata":{}},{"cell_type":"code","source":"print(\"First Image and Label\", show_data(train_dataset[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The label: \", train_dataset[0][1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"First Image and Label\", show_data(validation_dataset[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SoftMax Classifier Model","metadata":{}},{"cell_type":"code","source":"# Inherits nn.Module which is the base class for all neural networks\nclass SoftMax(nn.Module):\n    \n    # Constructor\n    def __init__(self, input_size, output_size):\n        super(SoftMax, self).__init__()\n        # Creates a layer of given input size and output size\n        self.linear = nn.Linear(input_size, output_size)\n        \n    # Prediction\n    def forward(self, x):\n        # Runs the x value through the single layers defined above\n        z = self.linear(x)\n        return z","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset[0][0].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#input is a 28 * 28 image, output is a probability array for each class\ninput_dim = 28 * 28\noutput_dim = 10","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Creation","metadata":{}},{"cell_type":"code","source":"model = SoftMax(input_dim, output_dim)\nprint(\"The model:\\n \", model)\nprint('W: ',list(model.parameters())[0].size())\nprint('b: ',list(model.parameters())[1].size())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Try the model with random weights first","metadata":{}},{"cell_type":"code","source":"# First we get the X value of the first image\nX = train_dataset[0][0]\n# We can see the shape is 1 by 28 by 28, we need it to be flattened to 1 by 28 * 28 (784)\nprint(X.shape)\nX = X.view(-1, 28*28)\nprint(X.shape)\n# Now we can make a prediction, each class has a value, and the higher it is the more confident the model is that it is that digit\nmodel(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Define the learning rate, optimizer, criterion, and data loader","metadata":{}},{"cell_type":"code","source":"learning_rate = 0.1\n# The optimizer will updates the model parameters using the learning rate\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n# The criterion will measure the loss between the prediction and actual label values\n# This is where the SoftMax occurs, it is built into the Criterion Cross Entropy Loss\ncriterion = nn.CrossEntropyLoss()\n# Created a training data loader so we can set the batch size\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100)\n# Created a validation data loader so we can set the batch size\nvalidation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"n_epochs = 30\n# Lists to keep track of loss and accuracy\nloss_list = []\naccuracy_list = []\nspeed_list=[]\nmemory_list=[]\nsize_list=[]\n# Size of the validation data\nN_test = len(validation_dataset)\n\n#monitor memory usage\npeak_gpu_memory_used =0\ncpu_memory_used=0\n# Function to train the model based on number of epochs\ndef train_model(n_epochs):\n    # Loops n_epochs times\n    for epoch in range(n_epochs):\n        start_time = time.time()\n        # For each batch in the train loader\n        for x, y in train_loader:\n            # Resets the calculated gradient value, this must be done each time as it accumulates if we do not reset\n            optimizer.zero_grad()\n            # Makes a prediction based on the image tensor\n            z = model(x.view(-1, 28 * 28))\n            # Calculates loss between the model output and actual class\n            loss = criterion(z, y)\n            # Calculates the gradient value with respect to each weight and bias\n            loss.backward()\n            # Updates the weight and bias according to calculated gradient value\n            optimizer.step()\n        \n        # Each epoch we check how the model performs with data it has not seen which is the validation data, we are not training here\n        correct = 0\n        # For each batch in the validation loader\n        for x_test, y_test in validation_loader:\n            # Makes prediction based on image tensor\n            z = model(x_test.view(-1, 28 * 28))\n            # Finds the class with the higest output\n            _, yhat = torch.max(z.data, 1)\n            # Checks if the prediction matches the actual class and increments correct if it does\n            correct += (yhat == y_test).sum().item()\n        # Calculates the accuracy by dividing correct by size of validation dataset\n        accuracy = correct / N_test\n        # Keeps track loss\n        loss_list.append(loss.data)\n        # Keeps track of the accuracy\n        accuracy_list.append(accuracy)\n        peak_gpu_memory_used= torch.cuda.max_memory_allocated()/ (1024 ** 3)\n        cpu_memory_used = psutil.virtual_memory().used / (1024 ** 3)\n        end_time = time.time()\n        epoch_time = end_time - start_time\n        speed_list.append(epoch_time)\n        memory_list.append(cpu_memory_used)\n\n        print(f\"Epoch {epoch+1}/{n_epochs} - Time: {epoch_time:.2f} seconds\")\n        print(f\"Accuracy : {accuracy}\")\n        print()\n        \n#     print(f\"Peak GPU Memory Used: {peak_gpu_memory_used:.2f} GB\")\n    print(f\"CPU Memory Used: {cpu_memory_used:.2f} GB\")\n\n# Function call\ntrain_model(n_epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model_size(model):\n    n_params=0\n    params = np.sum(p.numel() for p in model.parameters())\n    print(\"pparams:\",params)\n\n    size_bytes = params * 4  # Assuming float32 parameters (4 bytes per parameter)\n    size_MB = size_bytes / (1024 ** 2)  # Convert to MB\n    \n                    \n    \n    return size_MB, n_params\n\nmodel_size_1, params_number = get_model_size(model)\nprint(f\"Model Size: {model_size_1:.2f} MB\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot the loss and accuracy","metadata":{}},{"cell_type":"code","source":"# Plot the loss and accuracy\n\nfig, ax1 = plt.subplots()\ncolor = 'tab:red'\nax1.plot(loss_list,color=color)\nax1.set_xlabel('epoch',color=color)\nax1.set_ylabel('total loss',color=color)\nax1.tick_params(axis='y', color=color)\n    \nax2 = ax1.twinx()  \ncolor = 'tab:blue'\nax2.set_ylabel('accuracy', color=color)  \nax2.plot( accuracy_list, color=color)\nax2.tick_params(axis='y', color=color)\nfig.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot the speed and accuracy","metadata":{}},{"cell_type":"code","source":"fig, ax1 = plt.subplots()\ncolor = 'tab:red'\nax1.plot(speed_list,color=color)\nax1.set_xlabel('epoch',color=color)\nax1.set_ylabel('speed',color=color)\nax1.tick_params(axis='y', color=color)\n    \nax2 = ax1.twinx()  \ncolor = 'tab:blue'\nax2.set_ylabel('accuracy', color=color)  \nax2.plot( accuracy_list, color=color)\nax2.tick_params(axis='y', color=color)\nfig.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot memory and accuracy","metadata":{}},{"cell_type":"code","source":"fig, ax1 = plt.subplots()\ncolor = 'tab:red'\nax1.plot(memory_list,color=color)\nax1.set_xlabel('epoch',color=color)\nax1.set_ylabel('memory',color=color)\nax1.tick_params(axis='y', color=color)\n    \nax2 = ax1.twinx()  \ncolor = 'tab:blue'\nax2.set_ylabel('accuracy', color=color)  \nax2.plot( accuracy_list, color=color)\nax2.tick_params(axis='y', color=color)\nfig.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test","metadata":{}},{"cell_type":"markdown","source":"### Before Quantization","metadata":{}},{"cell_type":"code","source":"model.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test=validation_dataset[0][0]\nx_test=x_test.view(-1, 28*28)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Quantazition ","metadata":{}},{"cell_type":"code","source":"quantized_model=torch.ao.quantization.quantize_dynamic(\n    model,  # the original model\n    {torch.nn.Linear},  # a set of layers to dynamically quantize\n    dtype=torch.float16)  # the target dtype for quantized weights\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After quantization is applied by going from float32 to float16, the model performance has not changed\nquantized_model(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#to fix: I was traying to get the size of the float16 model with this function\ndef get_model_size_f16(model):\n    params = np.sum(p.numel() for p in model.parameters())\n    print(\"pparams:\",params)\n    size_bytes = params * 2  # Assuming float16 parameters (2 bytes per parameter)\n    print(f\"size_bytes:{size_bytes}\")\n    size_MB = size_bytes / (1024 ** 2)  # Convert to MB\n    \n    return size_MB","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here too\ndef get_parameter_element_size(model):\n    total_size_bytes = 0\n\n    for param in model.parameters():\n        element_size = param.element_size()\n        total_size_bytes += element_size\n\n    return total_size_bytes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_parameter_element_size(quantized_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_size_1 = get_model_size_f16(quantized_model)\nprint(f\"Quantized Model Size: {model_size_1:.10f} MB\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Trying to create a float16 version of the model from scratch and see if I can get the correct size (to be fixed)","metadata":{}},{"cell_type":"code","source":"# create float16 model\nclass SoftMaxFloat16(nn.Module):\n    # Constructor\n    def __init__(self, input_dim, output_dim):\n        super(SoftMaxFloat16, self).__init__()\n        # Creates a layer of given input size and output size with float16 data type\n        self.linear = nn.Linear(input_dim, output_dim).to(dtype=torch.float16)\n        \n    # Prediction\n    def forward(self, x):\n        # Runs the x value through the single layers defined above\n        z = self.linear(x)\n        return z","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_float16 = SoftMaxFloat16(input_dim, output_dim)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_size_1 = get_model_size_f16(model_float16)\nprint(f\"Quantized Model Size: {model_size_1:.10f} MB\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## I could get the size above(reduced by 2), but then the dtype on the training libs don't match...","metadata":{}},{"cell_type":"code","source":"n_epochs = 10\n# Lists to keep track of loss and accuracy\nloss_list = []\naccuracy_list = []\n# Size of the validation data\nN_test = len(validation_dataset)\n\n#monitor memory usage\npeak_gpu_memory_used =0\ncpu_memory_used=0\n# Function to train the model based on number of epochs\ndef train_model_16(n_epochs):\n    # Loops n_epochs times\n    for epoch in range(n_epochs):\n        start_time = time.time()\n        # For each batch in the train loader\n        for x, y in train_loader:\n            # Resets the calculated gradient value, this must be done each time as it accumulates if we do not reset\n            optimizer.zero_grad()\n            # Makes a prediction based on the image tensor\n            z = model_float16(x.view(-1, 28 * 28))\n            # Calculates loss between the model output and actual class\n            loss = criterion(z, y)\n            # Calculates the gradient value with respect to each weight and bias\n            loss.backward()\n            # Updates the weight and bias according to calculated gradient value\n            optimizer.step()\n        \n        # Each epoch we check how the model performs with data it has not seen which is the validation data, we are not training here\n        correct = 0\n        # For each batch in the validation loader\n        for x_test, y_test in validation_loader:\n            # Makes prediction based on image tensor\n            z = model_float16(x_test.view(-1, 28 * 28)) #MUST CHANGE DATA TYPE EVERYWHERE\n            # Finds the class with the higest output\n            _, yhat = torch.max(z.data, 1)\n            # Checks if the prediction matches the actual class and increments correct if it does\n            correct += (yhat == y_test).sum().item()\n        # Calculates the accuracy by dividing correct by size of validation dataset\n        accuracy = correct / N_test\n        # Keeps track loss\n        loss_list.append(loss.data)\n        # Keeps track of the accuracy\n        accuracy_list.append(accuracy)\n        peak_gpu_memory_used= torch.cuda.max_memory_allocated()/ (1024 ** 3)\n        cpu_memory_used = psutil.virtual_memory().used / (1024 ** 3)\n        end_time = time.time()\n        epoch_time = end_time - start_time\n\n        print(f\"Epoch {epoch+1}/{n_epochs} - Time: {epoch_time:.2f} seconds\")\n        print(f\"Accuracy : {accuracy}\")\n        print()\n        \n#     print(f\"Peak GPU Memory Used: {peak_gpu_memory_used:.2f} GB\")\n    print(f\"CPU Memory Used: {cpu_memory_used:.2f} GB\")\n\n# Function call\ntrain_model_16(n_epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}